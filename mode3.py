"""
Mode 3: So sÃ¡nh word-by-word giá»¯a 2 PDF vÃ  annotate highlight.
Refactor tá»« tool_compare_assemblage.py vá»›i enhanced logic:

Features:
- Word-by-word comparison vá»›i difflib SequenceMatcher
- 3 loáº¡i thay Ä‘á»•i vá»›i mÃ u sáº¯c rÃµ rÃ ng:
  
  ğŸ”´ Äá» (REPLACED): Text bá»‹ THAY Äá»”I
     - Text á»Ÿ cÃ¹ng vá»‹ trÃ­ nhÆ°ng ná»™i dung khÃ¡c nhau
     - TÃ´ Ä‘á» trÃªn Cáº¢ 2 PDF (Ref vÃ  Final)
     - Hiá»ƒn thá»‹ text cÅ© vÃ  text má»›i trong annotation
  
  ğŸŸ¡ VÃ€NG (MISSING): Text bá»‹ XÃ“A
     - Text cÃ³ trong Reference nhÆ°ng KHÃ”NG cÃ³ trong Final
     - TÃ´ vÃ ng chá»‰ trÃªn PDF Reference
  
  ğŸŸ¢ XANH (EXTRA): Text Ä‘Æ°á»£c THÃŠM
     - Text cÃ³ trong Final nhÆ°ng KHÃ”NG cÃ³ trong Reference
     - TÃ´ xanh chá»‰ trÃªn PDF Final
"""

from __future__ import annotations

from typing import Dict, List, Tuple

import fitz  # PyMuPDF

from pdf_optimizer import smart_preprocess

CASE_INSENSITIVE = True
IGNORE_QUOTES = True


def _normalize_word(word: str) -> str:
    import unicodedata
    
    if CASE_INSENSITIVE:
        word = word.lower()
    
    if IGNORE_QUOTES:
        # XÃ“A quotes/apostrophes TRÆ¯á»šC normalize Ä‘á»ƒ trÃ¡nh táº¡o combining chars
        pre_normalize_chars = ["'", "'", "'", "`", "Â´"]
        for char in pre_normalize_chars:
            word = word.replace(char, "")
        
        # SAU ÄÃ“ má»›i normalize Unicode
        word = unicodedata.normalize('NFKC', word)
        # XÃ“A Háº¾T Táº¤T Cáº¢ cÃ¡c loáº¡i apostrophe, quotes, accents
        # KhÃ´ng replace vá» ' mÃ  XÃ“A LUÃ”N Ä‘á»ƒ: d'emploi â†’ demploi
        chars_to_remove = [
            "'",  # Normal apostrophe
            "'",  # U+2019 Right single quotation mark
            "'",  # U+2018 Left single quotation mark  
            "Ê¼",  # U+02BC Modifier letter apostrophe
            "`",  # U+0060 Grave accent / Backtick
            "Â´",  # U+00B4 Acute accent
            "ËŠ",  # U+02CA Modifier letter acute accent
            "Ë‹",  # U+02CB Modifier letter grave accent
            "Ê¹",  # U+02B9 Modifier letter prime
            "â€²",  # U+2032 Prime
            "â€µ",  # U+2035 Reversed prime
            "ï¼‡", # U+FF07 Fullwidth apostrophe
            "Õš",  # U+055A Armenian apostrophe
            "ê‹",  # U+A78B Latin capital letter saltillo
            "êŒ",  # U+A78C Latin small letter saltillo
            "Ê»",  # U+02BB Modifier letter turned comma
            "Ê½",  # U+02BD Modifier letter reversed comma
            "\u0301",  # Combining acute accent
            "\u0300",  # Combining grave accent
            '"',  # Normal double quote
            """,  # U+201C Left double quotation mark
            """,  # U+201D Right double quotation mark
            "Â«",  # Left-pointing double angle quotation mark
            "Â»",  # Right-pointing double angle quotation mark
            "â€",  # Double low-9 quotation mark
            "â€Ÿ",  # Double high-reversed-9 quotation mark
            "ã€", # U+301D Reversed double prime quotation mark
            "ã€", # U+301E Double prime quotation mark
            "ï¼‚", # U+FF02 Fullwidth quotation mark
        ]
        
        # XÃ“A táº¥t cáº£
        for char in chars_to_remove:
            word = word.replace(char, "")
        
        # NORMALIZE SUPERSCRIPT/SUBSCRIPT vá» dáº¡ng thÆ°á»ng
        # VD: "PLUSâ½Â¹â¾" â†’ "PLUS(1)"
        superscript_map = {
            'â°': '0', 'Â¹': '1', 'Â²': '2', 'Â³': '3', 'â´': '4',
            'âµ': '5', 'â¶': '6', 'â·': '7', 'â¸': '8', 'â¹': '9',
            'â½': '(', 'â¾': ')', 'âº': '+', 'â»': '-', 'â¼': '=',
        }
        subscript_map = {
            'â‚€': '0', 'â‚': '1', 'â‚‚': '2', 'â‚ƒ': '3', 'â‚„': '4',
            'â‚…': '5', 'â‚†': '6', 'â‚‡': '7', 'â‚ˆ': '8', 'â‚‰': '9',
            'â‚': '(', 'â‚': ')', 'â‚Š': '+', 'â‚‹': '-', 'â‚Œ': '=',
        }
        
        for sup, normal in superscript_map.items():
            word = word.replace(sup, normal)
        for sub, normal in subscript_map.items():
            word = word.replace(sub, normal)
        
        # XÃ“A HOÃ€N TOÃ€N patterns (sá»‘ nhá») - VD: (1), (2), (12) Ä‘á»ƒ ignore trong comparison
        # NhÆ°ng GIá»® numbers lá»›n nhÆ° 32859, 61545
        # DÃ¹ng regex Ä‘á»ƒ tÃ¬m vÃ  xÃ³a: (1-2 chá»¯ sá»‘)
        import re
        word = re.sub(r'\([0-9]{1,2}\)', '', word)  # XÃ³a (1), (2), (12), etc.
        word = re.sub(r'\[[0-9]{1,2}\]', '', word)  # XÃ³a [1], [2], etc.
        word = re.sub(r'\{[0-9]{1,2}\}', '', word)  # XÃ³a {1}, {2}, etc.
        
        # XÃ“A Táº¤T Cáº¢ PUNCTUATION cÃ²n láº¡i (dáº¥u cháº¥m, dáº¥u pháº©y, v.v...)
        # Category 'P' = Punctuation: . , ; : ! ? - ...
        word = ''.join(c for c in word if not unicodedata.category(c).startswith('P'))
        
        # Remove zero-width characters
        word = word.replace("\u200b", "")  # Zero-width space
        word = word.replace("\u200c", "")  # Zero-width non-joiner
        word = word.replace("\u200d", "")  # Zero-width joiner
        word = word.replace("\ufeff", "")  # Zero-width no-break space
        
        # Remove báº¥t ká»³ combining marks cÃ²n láº¡i
        word = ''.join(c for c in word if unicodedata.category(c) != 'Mn')
        
        # XÃ“A Háº¾T SPACES
        # VD: "PLUS(1)" â†’ "PLUS 1" â†’ "PLUS1"
        #     "PLUSâ½Â¹â¾" â†’ "PLUS(1)" â†’ "PLUS 1" â†’ "PLUS1"
        word = word.replace(' ', '').strip()
    
    return word


def extract_page_words_with_boxes(pdf_path: str) -> List[Dict]:
    doc = fitz.open(pdf_path)
    pages: List[Dict] = []
    for page_index in range(doc.page_count):
        page = doc.load_page(page_index)
        words_raw = page.get_text("words")
        words = []
        for x0, y0, x1, y1, text, *_ in words_raw:
            words.append(
                {"text": text, "rect": fitz.Rect(x0, y0, x1, y1), "highlight_color": None}
            )
        pages.append({"page": page_index, "words": words})
    doc.close()
    return pages


def preprocess_merge_parentheses(words_data: List[Dict]) -> List[Dict]:
    """
    Pre-process: Merge patterns nhÆ° "PLUS" + "(1)" thÃ nh "PLUS(1)" TRÆ¯á»šC KHI normalize.
    
    VD: ["PLUS", "(1)"] â†’ ["PLUS(1)"]
        ["PLUS", "â½Â¹â¾"] â†’ ["PLUSâ½Â¹â¾"]
    """
    import re
    
    if not words_data:
        return words_data
    
    merged = []
    i = 0
    
    while i < len(words_data):
        current = words_data[i]
        
        # Check náº¿u word tiáº¿p theo lÃ  pattern: (sá»‘) hoáº·c â½sá»‘â¾
        if i + 1 < len(words_data):
            next_word = words_data[i + 1]
            next_text = next_word["text"]
            
            # Pattern: (1), (2), â½Â¹â¾, â½Â²â¾, etc. (chá»‰ cÃ³ sá»‘ 1-2 chá»¯ sá»‘ trong ngoáº·c)
            if re.match(r'^[\(â½][0-9â°Â¹Â²Â³â´âµâ¶â·â¸â¹]{1,2}[\)â¾]$', next_text):
                # MERGE: "PLUS" + "(1)" â†’ "PLUS(1)"
                merged_text = current["text"] + next_text
                merged_rect = fitz.Rect(current["rect"]) | fitz.Rect(next_word["rect"])
                
                merged.append({
                    "text": merged_text,
                    "rect": merged_rect,
                    "highlight_color": None
                })
                i += 2  # Skip cáº£ 2 words
                continue
        
        # KhÃ´ng merge, giá»¯ nguyÃªn
        merged.append(current)
        i += 1
    
    return merged


def align_words_assemblage(ref_words_data: List[Dict], final_words_data: List[Dict]):
    """
    So sÃ¡nh word-by-word vá»›i 3 loáº¡i thay Ä‘á»•i:
    
    1. REPLACED (Äá»): Text bá»‹ THAY Äá»”I (cÃ¹ng vá»‹ trÃ­ nhÆ°ng khÃ¡c ná»™i dung)
       - TÃ´ Äá» trÃªn Cáº¢ 2 PDF (Ref vÃ  Final)
    
    2. MISSING (VÃ€NG): Text cÃ³ trong Reference nhÆ°ng KHÃ”NG cÃ³ trong Final
       - TÃ´ VÃ€NG trÃªn PDF Reference
    
    3. EXTRA (XANH): Text cÃ³ trong Final nhÆ°ng KHÃ”NG cÃ³ trong Reference
       - TÃ´ XANH trÃªn PDF Final
       
    POST-PROCESSING: Loáº¡i bá» highlight náº¿u text giá»‘ng nhau á»Ÿ cáº£ 2 PDFs
    """
    from difflib import SequenceMatcher

    # PRE-PROCESS: Merge "PLUS" + "(1)" â†’ "PLUS(1)"
    ref_words_data = preprocess_merge_parentheses(ref_words_data)
    final_words_data = preprocess_merge_parentheses(final_words_data)

    # Normalize for comparison
    ref_norm = [_normalize_word(w["text"]) for w in ref_words_data]
    final_norm = [_normalize_word(w["text"]) for w in final_words_data]

    s = SequenceMatcher(None, ref_norm, final_norm)
    opcodes = list(s.get_opcodes())
    
    # DISABLE REPLACE MERGE
    # Chá»‰ giá»¯ DELETE (MISSING - mÃ u vÃ ng) vÃ  INSERT (EXTRA - mÃ u xanh)
    # KhÃ´ng merge thÃ nh REPLACE (mÃ u Ä‘á») vÃ¬ gÃ¢y nhiá»u false positives
    merged_opcodes = opcodes
    
    # Process opcodes
    idx1_current = 0
    idx2_current = 0

    for tag, i1, i2, j1, j2 in merged_opcodes:
        if tag == "equal":
            # Skip - text giá»‘ng nhau, khÃ´ng cáº§n highlight
            idx1_current += i2 - i1
            idx2_current += j2 - j1

        elif tag == "delete":
            # MISSING TEXT: Text chá»‰ cÃ³ trong Reference
            # TÃ´ VÃ€NG trÃªn Reference
            for k in range(i2 - i1):
                ref_words_data[idx1_current + k]["highlight_color"] = "yellow"
                ref_words_data[idx1_current + k]["change_type"] = "MISSING"
            idx1_current += i2 - i1

        elif tag == "insert":
            # EXTRA TEXT: Text chá»‰ cÃ³ trong Final
            # TÃ´ XANH trÃªn Final
            for k in range(j2 - j1):
                final_words_data[idx2_current + k]["highlight_color"] = "green"
                final_words_data[idx2_current + k]["change_type"] = "EXTRA"
            idx2_current += j2 - j1

        elif tag == "replace":
            # TREAT REPLACE AS DELETE + INSERT
            # Pháº§n bá»‹ xÃ³a: TÃ´ VÃ€NG trÃªn Ref
            for k in range(i2 - i1):
                ref_words_data[idx1_current + k]["highlight_color"] = "yellow"
                ref_words_data[idx1_current + k]["change_type"] = "MISSING"
            
            # Pháº§n Ä‘Æ°á»£c thÃªm: TÃ´ XANH trÃªn Final
            for k in range(j2 - j1):
                final_words_data[idx2_current + k]["highlight_color"] = "green"
                final_words_data[idx2_current + k]["change_type"] = "EXTRA"

            idx1_current += i2 - i1
            idx2_current += j2 - j1

    # POST-PROCESSING: Loáº¡i bá» highlights cho words cÃ³ text GIá»NG NHAU
    # Má»¥c Ä‘Ã­ch: TrÃ¡nh tÃ´ mÃ u cho '32859' khi nÃ³ cÃ³ á»Ÿ cáº£ 2 PDF
    remove_same_text_highlights(ref_words_data, final_words_data)

    return ref_words_data, final_words_data


def remove_same_text_highlights(ref_words_data: List[Dict], final_words_data: List[Dict]):
    """
    Loáº¡i bá» highlights cho cÃ¡c words cÃ³ text giá»‘ng nhau trong cáº£ 2 PDFs.
    
    Logic:
    - Thu tháº­p Táº¤T Cáº¢ normalized texts tá»« cáº£ 2 PDFs (ALL words, khÃ´ng chá»‰ highlighted)
    - TÃ¬m common texts (texts xuáº¥t hiá»‡n á»Ÿ Cáº¢ 2 PDFs)
    - Náº¿u 1 highlighted word náº±m trong common texts â†’ XÃ“A highlight
    
    VÃ­ dá»¥: '0,00' xuáº¥t hiá»‡n nhiá»u láº§n á»Ÿ cáº£ 2 PDF â†’ khÃ´ng tÃ´ mÃ u
            '32859' cÃ³ á»Ÿ cáº£ Ref vÃ  Final â†’ khÃ´ng tÃ´ mÃ u
    """
    # Thu tháº­p Táº¤T Cáº¢ normalized texts tá»« Cáº¢ 2 PDFs (khÃ´ng phÃ¢n biá»‡t highlighted hay khÃ´ng)
    all_ref_norm_set = set()
    all_final_norm_set = set()
    
    for w in ref_words_data:
        norm_text = _normalize_word(w["text"])
        if norm_text:  # Chá»‰ add náº¿u khÃ´ng rá»—ng
            all_ref_norm_set.add(norm_text)
    
    for w in final_words_data:
        norm_text = _normalize_word(w["text"])
        if norm_text:
            all_final_norm_set.add(norm_text)
    
    # Thu tháº­p concatenated versions cá»§a HIGHLIGHTED consecutive words
    # VD: ["PLUS", "(1)"] highlighted â†’ cÅ©ng add "plus" vÃ o check
    for i in range(len(ref_words_data) - 1):
        if ref_words_data[i].get("highlight_color") and ref_words_data[i+1].get("highlight_color"):
            concat = _normalize_word(ref_words_data[i]["text"]) + _normalize_word(ref_words_data[i+1]["text"])
            if concat:
                all_ref_norm_set.add(concat)
    
    for i in range(len(final_words_data) - 1):
        if final_words_data[i].get("highlight_color") and final_words_data[i+1].get("highlight_color"):
            concat = _normalize_word(final_words_data[i]["text"]) + _normalize_word(final_words_data[i+1]["text"])
            if concat:
                all_final_norm_set.add(concat)
    
    # TÃ¬m COMMON texts: texts xuáº¥t hiá»‡n á»Ÿ Cáº¢ 2 PDFs
    common_texts = all_ref_norm_set & all_final_norm_set
    
    if not common_texts:
        return
    
    # Loáº¡i bá» highlight cho cÃ¡c words cÃ³ normalized text náº±m trong common_texts
    for w in ref_words_data:
        if w.get("highlight_color"):
            norm_text = _normalize_word(w["text"])
            if norm_text and norm_text in common_texts:
                w["highlight_color"] = None
                w["change_type"] = None
    
    for w in final_words_data:
        if w.get("highlight_color"):
            norm_text = _normalize_word(w["text"])
            if norm_text and norm_text in common_texts:
                w["highlight_color"] = None
                w["change_type"] = None
    
    # Check consecutive pairs: náº¿u concat cá»§a 2 words liÃªn tiáº¿p match vá»›i common_texts
    for i in range(len(ref_words_data) - 1):
        w1, w2 = ref_words_data[i], ref_words_data[i+1]
        if w1.get("highlight_color") and w2.get("highlight_color"):
            concat = _normalize_word(w1["text"]) + _normalize_word(w2["text"])
            if concat in common_texts:
                w1["highlight_color"] = None
                w1["change_type"] = None
                w2["highlight_color"] = None
                w2["change_type"] = None
    
    for i in range(len(final_words_data) - 1):
        w1, w2 = final_words_data[i], final_words_data[i+1]
        if w1.get("highlight_color") and w2.get("highlight_color"):
            concat = _normalize_word(w1["text"]) + _normalize_word(w2["text"])
            if concat in common_texts:
                w1["highlight_color"] = None
                w1["change_type"] = None
                w2["highlight_color"] = None
                w2["change_type"] = None


def merge_adjacent_words(words_data: List[Dict]) -> List[Dict]:
    """
    Gá»™p cÃ¡c words liá»n ká» cÃ¹ng hÃ ng vÃ  cÃ¹ng mÃ u thÃ nh má»™t annotation dÃ i ngang.
    
    Args:
        words_data: Danh sÃ¡ch words vá»›i rect, highlight_color, change_type
    
    Returns:
        Danh sÃ¡ch merged annotations (má»—i item lÃ  má»™t group gá»™p)
    """
    # Chá»‰ láº¥y cÃ¡c words cÃ³ highlight
    highlighted_words = [w for w in words_data if w.get("highlight_color")]
    
    if not highlighted_words:
        return []
    
    # Sort theo y (top), rá»“i x (left) Ä‘á»ƒ xá»­ lÃ½ theo thá»© tá»± Ä‘á»c
    highlighted_words.sort(key=lambda w: (w["rect"].y0, w["rect"].x0))
    
    merged_groups = []
    current_group = None
    
    VERTICAL_THRESHOLD = 5    # pixels - cÃ¹ng hÃ ng náº¿u y chÃªnh lá»‡ch < 5px
    HORIZONTAL_GAP = 20       # pixels - merge náº¿u khoáº£ng cÃ¡ch ngang < 20px
    
    for word in highlighted_words:
        if current_group is None:
            # Báº¯t Ä‘áº§u group má»›i
            current_group = {
                "rect": fitz.Rect(word["rect"]),
                "highlight_color": word["highlight_color"],
                "change_type": word.get("change_type"),
                "texts": [word["text"]],
                "replaced_with": word.get("replaced_with"),
                "replaced_from": word.get("replaced_from"),
            }
        else:
            # Kiá»ƒm tra xem cÃ³ thá»ƒ merge vá»›i group hiá»‡n táº¡i khÃ´ng
            same_row = abs(word["rect"].y0 - current_group["rect"].y0) < VERTICAL_THRESHOLD
            same_color = word["highlight_color"] == current_group["highlight_color"]
            same_type = word.get("change_type") == current_group.get("change_type")
            horizontal_gap = word["rect"].x0 - current_group["rect"].x1
            close_enough = horizontal_gap < HORIZONTAL_GAP
            
            if same_row and same_color and same_type and close_enough:
                # Merge vÃ o group hiá»‡n táº¡i
                current_group["rect"] = current_group["rect"] | word["rect"]  # Union cá»§a 2 rects
                current_group["texts"].append(word["text"])
                # Cáº­p nháº­t replaced info náº¿u cÃ³
                if word.get("replaced_with"):
                    current_group["replaced_with"] = word.get("replaced_with")
                if word.get("replaced_from"):
                    current_group["replaced_from"] = word.get("replaced_from")
            else:
                # LÆ°u group hiá»‡n táº¡i vÃ  báº¯t Ä‘áº§u group má»›i
                merged_groups.append(current_group)
                current_group = {
                    "rect": fitz.Rect(word["rect"]),
                    "highlight_color": word["highlight_color"],
                    "change_type": word.get("change_type"),
                    "texts": [word["text"]],
                    "replaced_with": word.get("replaced_with"),
                    "replaced_from": word.get("replaced_from"),
                }
    
    # Äá»«ng quÃªn group cuá»‘i cÃ¹ng
    if current_group:
        merged_groups.append(current_group)
    
    return merged_groups


def apply_highlights_to_page(page: fitz.Page, words_data: List[Dict], page_num: int) -> int:
    """
    Apply highlights to a PDF page with detailed change type information.
    Gá»™p cÃ¡c annotations liá»n ká» cÃ¹ng hÃ ng thÃ nh má»™t annotation dÃ i ngang.
    
    MÃ u sáº¯c:
    - Äá»: Text REPLACED (Ref vÃ  Final khÃ¡c nhau)
    - VÃ€NG: Text MISSING (Ref cÃ³, Final khÃ´ng cÃ³)
    - XANH: Text EXTRA (Final cÃ³, Ref khÃ´ng cÃ³)
    
    Note: Logic thÃ´ng minh - khÃ´ng tÃ´ mÃ u náº¿u text giá»‘ng nhau á»Ÿ cáº£ 2 PDFs
    """
    # Color map
    color_map = {
        "red": (1.0, 0.4, 0.4),      # Äá» - Text bá»‹ thay Ä‘á»•i (REPLACED)
        "yellow": (1.0, 1.0, 0.4),   # VÃ ng - Text bá»‹ xÃ³a (MISSING)
        "green": (0.5, 1.0, 0.5),    # Xanh lÃ¡ - Text Ä‘Æ°á»£c thÃªm (EXTRA)
    }

    highlights_added = 0
    
    # MERGE cÃ¡c words liá»n ká» cÃ¹ng hÃ ng trÆ°á»›c khi apply annotation
    merged_groups = merge_adjacent_words(words_data)

    for group in merged_groups:
        color = color_map.get(group["highlight_color"])
        if not color:
            continue

        try:
            # Apply highlight cho toÃ n bá»™ merged rect
            annot = page.add_highlight_annot(group["rect"])
            annot.set_colors(stroke=color)
            annot.set_opacity(0.5)

            # Add detailed message based on change type
            change_type = group.get("change_type", "CHANGED")
            text_content = " ".join(group["texts"])  # Gá»™p táº¥t cáº£ texts trong group

            # Generate descriptive message
            if change_type == "REPLACED":
                title = "Mode3-MODIFIÃ‰"
                # Kiá»ƒm tra xem cÃ³ thÃ´ng tin replaced_with hoáº·c replaced_from khÃ´ng
                if "replaced_with" in group and group["replaced_with"]:
                    # ÄÃ¢y lÃ  text trong Reference Ä‘Ã£ bá»‹ thay Ä‘á»•i
                    content = (
                        f"ğŸ”´ TEXTE MODIFIÃ‰\n"
                        f"Ancien texte (RÃ©fÃ©rence): '{text_content}'\n"
                        f"Nouveau texte (Final): '{group['replaced_with']}'\n"
                        f"Statut: Texte a Ã©tÃ© MODIFIÃ‰"
                    )
                elif "replaced_from" in group and group["replaced_from"]:
                    # ÄÃ¢y lÃ  text trong Final (text má»›i)
                    content = (
                        f"ğŸ”´ TEXTE MODIFIÃ‰\n"
                        f"Ancien texte (RÃ©fÃ©rence): '{group['replaced_from']}'\n"
                        f"Nouveau texte (Final): '{text_content}'\n"
                        f"Statut: Texte a Ã©tÃ© MODIFIÃ‰"
                    )
                else:
                    content = (
                        f"ğŸ”´ TEXTE MODIFIÃ‰\n"
                        f"Texte: '{text_content}'\n"
                        f"Statut: Texte a Ã©tÃ© MODIFIÃ‰"
                    )
            elif change_type == "MISSING":
                title = "Mode3-MANQUANT"
                content = (
                    f"ğŸŸ¡ TEXTE MANQUANT\n"
                    f"Texte: '{text_content}'\n"
                    f"Statut: PrÃ©sent dans RÃ©fÃ©rence mais PAS dans Final\n"
                    f"Action: Texte a Ã©tÃ© SUPPRIMÃ‰"
                )
            elif change_type == "EXTRA":
                title = "Mode3-SUPPLÃ‰MENTAIRE"
                content = (
                    f"ğŸŸ¢ TEXTE SUPPLÃ‰MENTAIRE\n"
                    f"Texte: '{text_content}'\n"
                    f"Statut: PrÃ©sent dans Final mais PAS dans RÃ©fÃ©rence\n"
                    f"Action: Texte a Ã©tÃ© AJOUTÃ‰"
                )
            else:
                title = f"Mode3-{change_type}"
                content = f"Change: {change_type}\nText: '{text_content}'"

            annot.set_info(title=title, content=content)
            annot.update()
            highlights_added += 1
        except Exception as e:
            # Silent fail for individual highlights
            continue

    return highlights_added


def compare_pages_assemblage(
    ref_page: fitz.Page,
    ref_page_dict: Dict,
    final_page: fitz.Page,
    page_index: int,
) -> Tuple[int, int]:
    """
    So khá»›p word diff vÃ  annotate cho cáº£ ref_page vÃ  final_page. Tráº£ vá» sá»‘ highlight Ä‘Ã£ thÃªm.
    """
    ref_words_data = ref_page_dict["words"]

    final_words_raw = final_page.get_text("words")
    final_words_data = [
        {"text": t, "rect": fitz.Rect(x0, y0, x1, y1), "highlight_color": None}
        for x0, y0, x1, y1, t, *_ in final_words_raw
    ]

    align_words_assemblage(ref_words_data, final_words_data)

    ref_count = apply_highlights_to_page(ref_page, ref_words_data, page_index)
    final_count = apply_highlights_to_page(final_page, final_words_data, page_index)

    return ref_count, final_count


def compare_mode3(
    ref_pdf_path: str,
    final_pdf_path: str,
    output_ref: str | None = None,
    output_final: str | None = None,
) -> Dict:
    """
    Mode 3 â€“ Annotate cáº£ reference vÃ  final PDF vá»›i highlight diff.
    
    3 loáº¡i thay Ä‘á»•i:
    - ğŸ”´ Äá» (REPLACED): Text bá»‹ thay Ä‘á»•i (tÃ´ Ä‘á» trÃªn cáº£ 2 PDF)
    - ğŸŸ¡ VÃ€NG (MISSING): Text cÃ³ trong Ref nhÆ°ng khÃ´ng cÃ³ trong Final (tÃ´ vÃ ng trÃªn Ref)
    - ğŸŸ¢ XANH (EXTRA): Text cÃ³ trong Final nhÆ°ng khÃ´ng cÃ³ trong Ref (tÃ´ xanh trÃªn Final)
    
    Logic thÃ´ng minh: Text giá»‘ng nhau á»Ÿ cáº£ 2 PDFs sáº½ KHÃ”NG Ä‘Æ°á»£c tÃ´ mÃ u
    (VÃ­ dá»¥: '32859' cÃ³ á»Ÿ cáº£ 2 â†’ khÃ´ng highlight)
    
    Returns:
        Dict with output_ref, output_final, stats, and preprocessing metadata
    """
    # === SMART PREPROCESSING ===
    print("\n=== MODE 3: Comparaison mot-Ã -mot ===")
    ref_pdf_path, preprocess_metadata = smart_preprocess(ref_pdf_path, final_pdf_path)
    # ===========================
    
    ref_doc = fitz.open(ref_pdf_path)
    ref_pages_data = extract_page_words_with_boxes(ref_pdf_path)
    final_doc = fitz.open(final_pdf_path)

    num_pages = min(len(ref_pages_data), final_doc.page_count, ref_doc.page_count)

    if output_ref is None:
        output_ref = ref_pdf_path.rsplit(".", 1)[0] + "_mode3_ref.pdf"
    if output_final is None:
        output_final = final_pdf_path.rsplit(".", 1)[0] + "_mode3_final.pdf"

    ref_highlights = 0
    final_highlights = 0

    for i in range(num_pages):
        ref_page = ref_doc.load_page(i)
        ref_page_dict = ref_pages_data[i]
        final_page = final_doc.load_page(i)

        r_count, f_count = compare_pages_assemblage(ref_page, ref_page_dict, final_page, i)
        ref_highlights += r_count
        final_highlights += f_count

    ref_doc.save(output_ref, garbage=4, deflate=True)
    ref_doc.close()

    final_doc.save(output_final, garbage=4, deflate=True)
    final_doc.close()

    stats = {
        "total_pages": num_pages,
        "ref_highlights": ref_highlights,
        "final_highlights": final_highlights,
    }

    return {
        "output_ref": output_ref,
        "output_final": output_final,
        "stats": stats,
        "preprocessing": preprocess_metadata,  # NEW
    }


__all__ = [
    "compare_mode3",
    "extract_page_words_with_boxes",
    "align_words_assemblage",
    "apply_highlights_to_page",
    "compare_pages_assemblage",
]

